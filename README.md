# chestnut-detection

This is an implementation of the method proposed in
> Keyhan Najafian, Alireza Ghanbari, Ian Stavness, Lingling Jin, Gholam Hassan Shirdel, and Farhad Maleki. Semi-self-supervised Learning Approach for Wheat Head Detection using Extremely Small Number of Labeled Samples. In *Proceedings of the IEEE/CVF International Conference on Computer Vision*, pages 1342-1351, 2021.

0. Prepare your videos and organize them like this:
```
project_root
│   
└───back
│   │   background_video1.mp4
│   │   background_video2.mp4
│   │   ...
│   
└───field
│   │   field_video1.mp4
│   │   field_video2.mp4
│   │	...
│
└───rep # representative frames taken from each field video
│   │   field_video1_0031.png # [video_name]_[timestamp].png
│   │   field_video1_0118.png
│   │	field_video2_0005.png
│   │	...
│
└───mask
│   │   field_video1_0031.npy
│   │   field_video1_1018.npy
│   │	field_video2_0005.npy
│   │	...
│
└───labels.txt
```
Here, `labels.txt` is a text file which contains class labels. For example, if you are working on chestnut detection, it will look like this:
```
nut(fine)
nut(empty)
burr
burr+nut
```

1. Make pixel-wise annotation, just like you would do in semantic segmentation (but for  only a few frames in the video).

2. Export the labels in Pascal VOC format and put them in `mask` directory. If you have made the labels with [labelme](https://github.com/wkentaro/labelme), you can export them with the following command:
```
python labelme2voc.py [input_dir] dataset_voc --labels labels.txt
```
where`input_dir` is where you've put the `.json` files generated by labelme.
Now you've got `.npy` files in `dataset_voc/SegmentationClass`.
Note that `labelme2voc.py` is taken from [the original labelme repo](https://github.com/wkentaro/labelme/blob/main/examples/semantic_segmentation/labelme2voc.py) and fixed a little bit to handle wider range of images.

3. Generate a composite dataset & a dataset for the 1st step of domain adaptation with the following command.
```
python make_dataset.py -n [n_sample] -p [prob_1 prob_2 ... prob_n_class] --root [path to the root directory of your project] -o composite --verbose --bbox --cuda  --domain-adaptation domain_adaptation_1
```

